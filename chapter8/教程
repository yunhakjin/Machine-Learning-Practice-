线性回归：
   优点：结果易于理解，计算上不复杂
   缺点：对非线性的数据拟合不好
   适用数据类型： 数值型和标称型数据。吧

   线性回归意味着可以将输入项分别诚意一些常量，再将结果加起来得到输出。
   应当怎样从一大堆的数据里求出回归方程呢？嘉定输入数据存放在矩阵中，回归系数存放在向量w中。
   那么对于给定的数据x1,预测的结果将会通过Y1=XTw给出。现在的问题是，手里有一些x和对应的y，怎样才能找到
   w？一个常用的方式是找出时误差最小的w（真实值和预测值的平方误差）

局部加权线性回归：（LWLR）
   思想：再计算的过程中，给预测点附近的每个点赋予一定的权重，再这个数据集子集上基于最小均方差进行普通的回归。
   LWLR使用“核”来对附近的点赋予更高的权重。核的类型可以自由选择，最常用的核就是高斯核。

岭回归：
   核心思想：缩减系数
   说明：当数据的特征比样本点还多，计算系数的过程中会出现因为矩阵的逆（非满秩矩阵）求不出来而程序报错的情况
   主要方法：1.lasso 2.前向逐步回归
   简单来说：在矩阵计算上加一个自定义的数值，使得其能够求逆